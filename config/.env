# LLM Configuration (Local endpoint)
LLM_API_BASE=http://localhost:8078/v1
LLM_API_KEY=dummy_key
LLM_MODEL_NAME=gpt-4o-mini

# Embedding Service (Docker container)
EMBEDDING_API_URL=http://localhost:8080/embed

# HuggingFace (for downloading datasets)
# HF_TOKEN=your_token_here

# Other settings
CUDA_VISIBLE_DEVICES=0
