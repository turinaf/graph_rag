# LLM Configuration (Local endpoint)
LLM_API_BASE=http://localhost:8078/v1
LLM_API_KEY=dummy_key  # Some local LLMs still require this field
LLM_MODEL_NAME=gpt-4o-mini

# Embedding Service (Docker container)
EMBEDDING_API_URL=http://localhost:8080/embed

# Optional: OpenAI API (for comparison)
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_API_BASE=https://api.openai.com/v1

# HuggingFace (for downloading models/datasets)
HF_TOKEN=your_huggingface_token_here

# Other settings
CUDA_VISIBLE_DEVICES=0
